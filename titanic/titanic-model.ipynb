{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import fixed\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "exp_data = pd.read_csv(\"./train.csv\")\n",
    "X = pd.get_dummies(exp_data[features])\n",
    "age_column = [x for x in list(exp_data['Age']) if str(x) != 'nan']\n",
    "X = X.fillna({'Age':np.median(age_column)})\n",
    "y = exp_data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submition_data = pd.read_csv(\"./test.csv\")\n",
    "submition_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total experimental data 891\n",
      "training and validation num rows: 801\n",
      "test num rows: 90\n"
     ]
    }
   ],
   "source": [
    "test_per = 0.1\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test \\\n",
    "    = train_test_split(X, y, test_size=test_per, random_state=1)\n",
    "\n",
    "print('total experimental data', X.shape[0])\n",
    "print('training and validation num rows:', X_train_val.shape[0])\n",
    "print('test num rows:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Iteration\n",
      "num_estimators:  10\n",
      "Best accuracy so far: 0.8264660493827161\n",
      "==========================================\n",
      "Completed Iteration\n",
      "num_estimators:  20\n",
      "Best accuracy so far: 0.8302469135802469\n",
      "==========================================\n",
      "Completed Iteration\n",
      "num_estimators:  30\n",
      "Best accuracy so far: 0.8302469135802469\n",
      "==========================================\n",
      "Completed Iteration\n",
      "num_estimators:  50\n",
      "Best accuracy so far: 0.8364969135802469\n",
      "==========================================\n",
      "Completed Iteration\n",
      "num_estimators:  70\n",
      "Best accuracy so far: 0.8364969135802469\n",
      "==========================================\n",
      "Completed Iteration\n",
      "num_estimators:  100\n",
      "Best accuracy so far: 0.8364969135802469\n",
      "==========================================\n",
      "The highest average accuracy was produced with parameters,\n",
      "num_estimators:  50\n",
      "max_depth:  7\n",
      "Average Accuracy: 0.8364969135802469\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "num_folds = 10\n",
    "folds = np.array_split(range(X_train_val.shape[0]), num_folds)\n",
    "\n",
    "avg_errors = []\n",
    "num_est_param1 = []\n",
    "max_depth_param = []\n",
    "\n",
    "for num_estimators in [10, 20, 30, 50, 70, 100]:\n",
    "    for max_depth in range(1,20,2):\n",
    "        errors = []\n",
    "        for val_fold in range(len(folds)):\n",
    "            val_indicies = folds[val_fold]\n",
    "            X_val = X_train_val.iloc[val_indicies]\n",
    "            y_val = y_train_val.iloc[val_indicies]\n",
    "\n",
    "            train_indicies = sum([list(folds[fold_ind]) for fold_ind in range(len(folds))\\\n",
    "                                     if fold_ind != val_fold], [])\n",
    "\n",
    "            X_train = X_train_val.iloc[train_indicies]\n",
    "            y_train = y_train_val.iloc[train_indicies]\n",
    "\n",
    "            model = RandomForestClassifier(n_estimators=num_estimators, max_depth=max_depth, random_state=1)\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict(X_val)\n",
    "            assert(len(y_val) == len(predictions))\n",
    "            errors.append(sum([np.abs(y_val.iloc[i] - predictions[i]) for i in range(len(y_val))])/len(y_val))\n",
    "        num_est_param1.append(num_estimators)\n",
    "        max_depth_param.append(max_depth)\n",
    "        avg_errors.append(np.average(errors))\n",
    "        \n",
    "    print(\"Completed Iteration\")\n",
    "    print(\"num_estimators: \", num_estimators)\n",
    "    print(\"Best accuracy so far:\", 1 - min(avg_errors))\n",
    "    print(\"==========================================\")\n",
    "\n",
    "min_index = np.argmin(avg_errors)\n",
    "print(\"The highest average accuracy was produced with parameters,\")\n",
    "print(\"num_estimators: \", num_est_param1[min_index])\n",
    "print(\"max_depth: \", max_depth_param[min_index])\n",
    "print(\"Average Accuracy:\", 1 - avg_errors[min_index])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72909d0acc5544d6ac4dd4a0b2de536b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='estimators', options=(10, 20, 30, 50, 70, 100), value=10), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.display1(num_estimators)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts1 = list(set(num_est_param1))\n",
    "opts1.sort()\n",
    "slider1 = widgets.SelectionSlider(description='estimators', options=opts1)\n",
    "\n",
    "def display1(num_estimators):\n",
    "    indicies = [i for i, val in enumerate(num_est_param1) if val == num_estimators]\n",
    "    depth_sel = list(map(lambda ind: max_depth_param[ind], indicies))\n",
    "    errs_sel = list(map(lambda ind: avg_errors[ind], indicies))\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.set_xlabel('max depth')\n",
    "    ax1.set_ylabel('error')\n",
    "    ax1.plot(depth_sel, errs_sel)\n",
    "    \n",
    "interact(display1, num_estimators=slider1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Iteration\n",
      "num_estimators:  10\n",
      "Best accuracy so far: 0.8139814814814815\n",
      "==========================================\n",
      "Completed Iteration\n",
      "num_estimators:  20\n",
      "Best accuracy so far: 0.8139814814814815\n",
      "==========================================\n",
      "Completed Iteration\n",
      "num_estimators:  30\n",
      "Best accuracy so far: 0.8139814814814815\n",
      "==========================================\n",
      "Completed Iteration\n",
      "num_estimators:  50\n",
      "Best accuracy so far: 0.8139814814814815\n",
      "==========================================\n",
      "Completed Iteration\n",
      "num_estimators:  70\n",
      "Best accuracy so far: 0.8140277777777778\n",
      "==========================================\n",
      "Completed Iteration\n",
      "num_estimators:  100\n",
      "Best accuracy so far: 0.8140277777777778\n",
      "==========================================\n",
      "The highest average accuracy was produced with parameters,\n",
      "num_estimators:  70\n",
      "lr:  1.6857894736842105\n",
      "Average Accuracy: 0.8140277777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "num_folds = 10\n",
    "folds = np.array_split(range(X_train_val.shape[0]), num_folds)\n",
    "\n",
    "avg_errors = []\n",
    "num_est_param2 = []\n",
    "lr_param = []\n",
    "\n",
    "for num_estimators in [10, 20, 30, 50, 70, 100]:\n",
    "    for learning_rate in np.linspace(0.01,2, 20):\n",
    "        errors = []\n",
    "        for val_fold in range(len(folds)):\n",
    "            val_indicies = folds[val_fold]\n",
    "            X_val = X_train_val.iloc[val_indicies]\n",
    "            y_val = y_train_val.iloc[val_indicies]\n",
    "\n",
    "            train_indicies = sum([list(folds[fold_ind]) for fold_ind in range(len(folds))\\\n",
    "                                     if fold_ind != val_fold], [])\n",
    "\n",
    "            X_train = X_train_val.iloc[train_indicies]\n",
    "            y_train = y_train_val.iloc[train_indicies]\n",
    "\n",
    "            model = AdaBoostClassifier(n_estimators=num_estimators, learning_rate=learning_rate, random_state=1)\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict(X_val)\n",
    "            assert(len(y_val) == len(predictions))\n",
    "            errors.append(sum([np.abs(y_val.iloc[i] - predictions[i]) for i in range(len(y_val))])/len(y_val))\n",
    "        num_est_param2.append(num_estimators)\n",
    "        lr_param.append(learning_rate)\n",
    "        avg_errors.append(np.average(errors))\n",
    "        \n",
    "    print(\"Completed Iteration\")\n",
    "    print(\"num_estimators: \", num_estimators)\n",
    "    print(\"Best accuracy so far:\", 1 - min(avg_errors))\n",
    "    print(\"==========================================\")\n",
    "\n",
    "min_index = np.argmin(avg_errors)\n",
    "print(\"The highest average accuracy was produced with parameters,\")\n",
    "print(\"num_estimators: \", num_est_param2[min_index])\n",
    "print(\"lr: \", lr_param[min_index])\n",
    "print(\"Average Accuracy:\", 1 - avg_errors[min_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4f2fca02364bc9bf82c3d4edb31822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='estimators', options=(10, 20, 30, 50, 70, 100), value=10), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.display2(num_estimators)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts2 = list(set(num_est_param2))\n",
    "opts2.sort()\n",
    "slider2 = widgets.SelectionSlider(description='estimators', options=opts2)\n",
    "\n",
    "def display2(num_estimators):\n",
    "    indicies = [i for i, val in enumerate(num_est_param2) if val == num_estimators]\n",
    "    lr_sel = list(map(lambda ind: lr_param[ind], indicies))\n",
    "    errs_sel = list(map(lambda ind: avg_errors[ind], indicies))\n",
    "    #plt.xlabel('lr')\n",
    "    #plt.ylabel('error')\n",
    "    #plt.plot(lr_sel, errs_sel)\n",
    "    fig2, ax2 = plt.subplots()\n",
    "    ax2.set_xlabel('lr')\n",
    "    ax2.set_ylabel('error')\n",
    "    ax2.plot(lr_sel, errs_sel)\n",
    "    \n",
    "interact(display2, num_estimators=slider2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying what I learned, I will instead try to use python libraries to perform hyper parameter search on random forest. According to the documentation, Cross validation is performed automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "best max_depth: 10\n",
      "best n_estimators: 100\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "grid_search = {'max_depth': [5, 10], 'n_estimators':[1, 100]}\n",
    "model = GridSearchCV(estimator = clf, param_grid = grid_search, cv = 4, verbose = 5, n_jobs = -1)\n",
    "model.fit(X_train_val, y_train_val)\n",
    "print(\"best max_depth:\", model.best_estimator_.max_depth)\n",
    "print(\"best n_estimators:\", model.best_estimator_.n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best max_depth: 5\n",
      "best n_estimators: 46\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "#grid_search = {'max_depth': [5, 10], 'n_estimators':[1, 100]}\n",
    "param_grid = {'max_depth':range(1,20,2), 'n_estimators':range(1,100,5)}\n",
    "model = RandomizedSearchCV(clf,param_grid, cv = 2)\n",
    "model.fit(X_train_val, y_train_val)\n",
    "print(\"best max_depth:\", model.best_estimator_.max_depth)\n",
    "print(\"best n_estimators:\", model.best_estimator_.n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
